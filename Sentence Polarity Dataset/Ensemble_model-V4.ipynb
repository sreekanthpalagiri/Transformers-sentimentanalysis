{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ensemble_model-V4.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"x-pWzJpM16x-"},"source":["# Final Masters Project\n","\n","## Name: Sreekanth Palagiri, Student ID: R00184198\n","\n","## Project Topic: Evaluation of Ensemble Approach for Sentiment Analysis on a Small Dataset\n","\n","##NoteBook: Ensemble of Models\n"]},{"cell_type":"markdown","metadata":{"id":"-XI7x-Qu2OZB"},"source":["### **Mount google drive**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHAsUhPE2i45","executionInfo":{"status":"ok","timestamp":1620063364627,"user_tz":-60,"elapsed":770,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"f09a252b-6c98-493f-da93-1cd393196a69"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1qkvvFpJFzEo","executionInfo":{"status":"ok","timestamp":1620063372390,"user_tz":-60,"elapsed":8526,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"ae0c25dd-638a-49c0-fd6c-044af4dfb3c7"},"source":["!pip install flair\n","!pip install sentencepiece\n","!pip install transformer"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: flair in /usr/local/lib/python3.7/dist-packages (0.8.0.post1)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from flair) (6.0.1)\n","Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3.3)\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n","Requirement already satisfied: torch<=1.7.1,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.7.1)\n","Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.7.0)\n","Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.8)\n","Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.95)\n","Requirement already satisfied: gdown==3.12.2 in /usr/local/lib/python3.7/dist-packages (from flair) (3.12.2)\n","Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from flair) (1.5.10)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n","Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3)\n","Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.6.4)\n","Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from flair) (1.2.12)\n","Requirement already satisfied: janome in /usr/local/lib/python3.7/dist-packages (from flair) (0.4.1)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n","Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n","Requirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.19.5)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from flair) (0.0.8)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.1)\n","Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.5.1)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.41.1)\n","Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (2.25.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.7.1,>=1.5.0->flair) (3.7.4.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect->flair) (1.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.0.12)\n","Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.10.1)\n","Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (20.9)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.0.45)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.10.2)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.11.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.5.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2020.12.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.4.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement transformer (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for transformer\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Rl8ATw853CaQ"},"source":["### **Load Data and Preprocess**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272},"id":"KSX3LEp51eTF","executionInfo":{"status":"ok","timestamp":1620063372391,"user_tz":-60,"elapsed":8521,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"253f7873-cb12-45c9-f3e9-6cf695b80ef9"},"source":["import pandas as pd\n","import numpy as np\n","\n","df=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/Masters Project/Sentence Polarity Dataset/sentimentpolarity.csv\")\n","print(df.groupby(['label']).size())\n","df.head()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["label\n","0    1000\n","1    1000\n","dtype: int64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[ferrera] has the charisma of a young woman wh...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>both flawed and delayed , martin scorcese's ga...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>for his first attempt at film noir , spielberg...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>easily one of the best and most exciting movie...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>this director's cut -- which adds 51 minutes -...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0  [ferrera] has the charisma of a young woman wh...      1\n","1  both flawed and delayed , martin scorcese's ga...      1\n","2  for his first attempt at film noir , spielberg...      1\n","3  easily one of the best and most exciting movie...      1\n","4  this director's cut -- which adds 51 minutes -...      0"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"uRkI6SHk3Kwy"},"source":["**Preprocessor to Remove all special characters except emoticons**"]},{"cell_type":"code","metadata":{"id":"aLrMJ40C3GRb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620063372391,"user_tz":-60,"elapsed":8515,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"ab76d49c-0d3f-44d9-db85-f55cb64ad25d"},"source":["import re\n","\n","def preprocessor(text):\n","    text = re.sub('<[^>]*>', '', text)\n","    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n","    text = re.sub('[^A-Za-z0-9\\']+', ' ', text.lower()) +\\\n","        ' '.join(emoticons).replace('-', '')\n","    return text\n","\n","#'[^A-Za-z0-9\\']+'\n","\n","print(df['text'][19])\n","print(preprocessor(df['text'][19]))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["the only fun part of the movie is playing the obvious game . you try to guess the order in which the kids in the house will be gored . \n","the only fun part of the movie is playing the obvious game you try to guess the order in which the kids in the house will be gored \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VLkO7GvP3Vnp","executionInfo":{"status":"ok","timestamp":1620063372392,"user_tz":-60,"elapsed":8510,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["df['text'] = df['text'].apply(preprocessor)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0IESLSGz3jwd"},"source":["### **Seperate Into Train and Test Sets**"]},{"cell_type":"code","metadata":{"id":"iXpLQsbc9QTK","executionInfo":{"status":"ok","timestamp":1620063372392,"user_tz":-60,"elapsed":8507,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["df_train=df.iloc[0:int(len(df)*0.85)].reset_index(drop=True)\n","df_test=df.iloc[int(len(df)*0.85):].reset_index(drop=True)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"d5UA1-C53jBV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620063372776,"user_tz":-60,"elapsed":8887,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"2fac7c08-e548-40e4-e705-a5d940f6f232"},"source":["from sklearn.model_selection import train_test_split\n","\n","df_test, df_eval, sentiment_test, sentiment_eval = train_test_split(df_test['text'], df_test['label'], \n","                                                                      random_state=1, test_size=.30, \n","                                                                      shuffle=False)\n","\n","\n","print('Length of train set:',len(df_test),'Length of test set:',len(df_eval))\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Length of train set: 210 Length of test set: 90\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-KuyngUI31ZH"},"source":["### **Load All Models and Predict to prepare for Emsemble Model**\n","\n","****"]},{"cell_type":"markdown","metadata":{"id":"hNYhoDg34wGH"},"source":["**Flair Model**\n","\n"]},{"cell_type":"code","metadata":{"id":"kAHU6zQXE-rD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620063384533,"user_tz":-60,"elapsed":20638,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"cca1f515-cc50-4edd-d636-83a639abbbfd"},"source":["from flair.models import TextClassifier\n","\n","model_flair=TextClassifier.load('/content/gdrive/My Drive/Colab Notebooks/Masters Project/Sentence Polarity Dataset/Models/resources/taggers/trec/best-model.pt')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["2021-05-03 17:36:15,731 loading file /content/gdrive/My Drive/Colab Notebooks/Masters Project/Sentence Polarity Dataset/Models/resources/taggers/trec/best-model.pt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OUHjiyzS-JYJ"},"source":["**Bert Model**"]},{"cell_type":"code","metadata":{"id":"FbwwQudm5Icp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620063399922,"user_tz":-60,"elapsed":36021,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"36a83147-0635-46fd-fb54-7220ae9afd7a"},"source":["import torch\n","from transformers import BertForSequenceClassification \n","\n","bertmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n","                                                      num_labels=len(df.label.unique()),\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)\n","\n","bertmodel.load_state_dict(torch.load('/content/gdrive/My Drive/Colab Notebooks/Masters Project/Sentence Polarity Dataset/Models/BERT_ft_epoch8.model',map_location=torch.device('cpu')))\n","\n","device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","bertmodel.to(device)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"n5fYFCYvK2da"},"source":["**roBERTA Model**"]},{"cell_type":"code","metadata":{"id":"dO5Al_YUK8kr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620063417659,"user_tz":-60,"elapsed":53752,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"a2bcfa85-1d39-4d6f-9c4c-5c990cb453b2"},"source":["import torch\n","from transformers import RobertaForSequenceClassification \n","\n","robertamodel = RobertaForSequenceClassification.from_pretrained(\"roberta-base\",\n","                                                      num_labels=len(df.label.unique()),\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)\n","\n","robertamodel.load_state_dict(torch.load('/content/gdrive/My Drive/Colab Notebooks/Masters Project/Sentence Polarity Dataset/Models/roBERTa_ft_epoch8.model',map_location=torch.device('cpu')))\n","\n","device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","robertamodel.to(device)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"3jUSnEIInLKu"},"source":["**XLNet Model**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VxHpOq1HnRV1","executionInfo":{"status":"ok","timestamp":1620063435116,"user_tz":-60,"elapsed":71203,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"cf1dddfa-ace6-4257-f021-39f3ae38350e"},"source":["import torch\n","from transformers import XLNetForSequenceClassification \n","\n","xlnet = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased',\n","                                                      num_labels=len(df.label.unique()),\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)\n","\n","xlnet.load_state_dict(torch.load('/content/gdrive/My Drive/Colab Notebooks/Masters Project/Sentence Polarity Dataset/Models/XLnet_ft_epoch3.model',map_location=torch.device('cpu')))\n","\n","device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","xlnet.to(device)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["XLNetForSequenceClassification(\n","  (transformer): XLNetModel(\n","    (word_embedding): Embedding(32000, 768)\n","    (layer): ModuleList(\n","      (0): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (6): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (7): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (8): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (9): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (10): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (11): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (sequence_summary): SequenceSummary(\n","    (summary): Linear(in_features=768, out_features=768, bias=True)\n","    (first_dropout): Identity()\n","    (last_dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"cAu-6YAw2qyB"},"source":["### **Getting Predictions on Test Data Set**\n"]},{"cell_type":"markdown","metadata":{"id":"9-qYuZk5Ar-_"},"source":["**Flair Model**"]},{"cell_type":"code","metadata":{"id":"pyz7fySIQ-F1","executionInfo":{"status":"ok","timestamp":1620063435117,"user_tz":-60,"elapsed":71197,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["probas=[]\n","probas_eval=[]\n","predictions=[]\n","predictions_eval=[]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"LX-qP9bGAW6r","executionInfo":{"status":"ok","timestamp":1620063448785,"user_tz":-60,"elapsed":84861,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from flair.data import Sentence\n","\n","results=[]\n","for i in df_test.index:\n","    sentence=Sentence(df_test[i])\n","    model_flair.predict(sentence)\n","    if sentence.get_labels()[0].value=='Positive':\n","      score=1-sentence.get_labels()[0].score\n","    else:\n","      score=sentence.get_labels()[0].score\n","    results.append([score,1-score])\n","probas.append(np.array(results))"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"aq83Fqk4y3_D","executionInfo":{"status":"ok","timestamp":1620063448786,"user_tz":-60,"elapsed":84857,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds = np.argmax(np.array(results), axis=1).flatten()\n","predictions.append(preds)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3bpDt0UAjPE","executionInfo":{"status":"ok","timestamp":1620063454670,"user_tz":-60,"elapsed":90738,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["results=[]\n","for i in df_eval.index:\n","    sentence=Sentence(df_eval[i])\n","    model_flair.predict(sentence)\n","    if sentence.get_labels()[0].value=='Positive':\n","      score=1-sentence.get_labels()[0].score\n","    else:\n","      score=sentence.get_labels()[0].score\n","    results.append([score,1-score])\n","probas_eval.append(np.array(results))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"cLjP5oAWRLzR","executionInfo":{"status":"ok","timestamp":1620063454670,"user_tz":-60,"elapsed":90735,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds = np.argmax(np.array(results), axis=1).flatten()\n","predictions_eval.append(preds)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Myc8tQ7jKfFm"},"source":["**Bert Model**"]},{"cell_type":"code","metadata":{"id":"Aky8SJ0SKUsy","executionInfo":{"status":"ok","timestamp":1620063455052,"user_tz":-60,"elapsed":91112,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from transformers import BertTokenizer\n","\n","tokenizerbert = BertTokenizer.from_pretrained(\n","                  'bert-base-uncased',\n","                  do_lower_case=True) \n","\n","\n","encoded_data_test=tokenizerbert.batch_encode_plus(\n","                        df_test.values,              # Same we are doing for validation set.\n","                        add_special_tokens=True,\n","                        return_attention_mask=True,\n","                        padding='longest',\n","                        max_length=256,\n","                        truncation=True,\n","                        return_tensors='pt')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"GhD8kC7xLFhl","executionInfo":{"status":"ok","timestamp":1620063455053,"user_tz":-60,"elapsed":91107,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n","\n","input_ids_test= encoded_data_test['input_ids']\n","attention_masks_test= encoded_data_test['attention_mask']\n","\n","dataset_test= TensorDataset(input_ids_test, attention_masks_test,)\n","\n","dataloader_test = DataLoader(\n","    dataset_test, \n","    sampler=SequentialSampler(dataset_test), \n","    batch_size=4\n","    )"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"D23WvGA7Axq9","executionInfo":{"status":"ok","timestamp":1620063455053,"user_tz":-60,"elapsed":91104,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["encoded_data_eval=tokenizerbert.batch_encode_plus(\n","                        df_eval.values,              # Same we are doing for validation set.\n","                        add_special_tokens=True,\n","                        return_attention_mask=True,\n","                        padding='longest',\n","                        max_length=256,\n","                        truncation=True,\n","                        return_tensors='pt')\n","\n","input_ids_eval= encoded_data_eval['input_ids']\n","attention_masks_eval= encoded_data_eval['attention_mask']\n","\n","dataset_eval= TensorDataset(input_ids_eval, attention_masks_eval,)\n","\n","dataloader_eval = DataLoader(\n","    dataset_eval, \n","    sampler=SequentialSampler(dataset_eval), \n","    batch_size=4\n","    )"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"dqC8_gq1MRmt","executionInfo":{"status":"ok","timestamp":1620063455054,"user_tz":-60,"elapsed":91101,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["import torch.nn.functional as F\n","\n","def predict_bert(dataloader_test):\n","  \n","    bertmodel.eval()\n","    all_logits = []\n","    \n","    for batch in dataloader_test:\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {\n","            'input_ids':      batch[0],\n","            'attention_mask': batch[1],\n","            }\n","\n","        with torch.no_grad():        \n","            outputs = bertmodel(**inputs)\n","            \n","        # since we have no loss, the only thing returned is logits\n","        logits = outputs[0]\n","        all_logits.append(logits)\n","    \n","    all_logits = torch.cat(all_logits, dim=0)\n","    preds_flat = np.argmax(all_logits.cpu().numpy(), axis=1).flatten()\n","\n","    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n","\n","    # get highest prob dimension as prediction\n","    \n","    return preds_flat, probs\n","\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ex20mNazM5oD","executionInfo":{"status":"ok","timestamp":1620063495684,"user_tz":-60,"elapsed":131728,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds, probs=predict_bert(dataloader_test)\n","probas.append(probs) \n","predictions.append(preds)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ci_7dSI9A7Yk","executionInfo":{"status":"ok","timestamp":1620063511051,"user_tz":-60,"elapsed":147091,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds, probs=predict_bert(dataloader_eval)\n","probas_eval.append(probs) \n","predictions_eval.append(preds)"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n3Ltb6sFMCEU"},"source":["**roBERTa Model**"]},{"cell_type":"code","metadata":{"id":"5UHr8YkbMHlZ","executionInfo":{"status":"ok","timestamp":1620063511455,"user_tz":-60,"elapsed":147492,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from transformers import RobertaTokenizer\n","\n","tokenizerroberta = RobertaTokenizer.from_pretrained(\n","                  'roberta-base') \n","\n","\n","encoded_data_test_r=tokenizerroberta.batch_encode_plus(\n","                        df_test.values,              # Same we are doing for validation set.\n","                        add_special_tokens=True,\n","                        return_attention_mask=True,\n","                        padding='longest',\n","                        max_length=256,\n","                        truncation=True,\n","                        return_tensors='pt')"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICJ24_4_NkIq","executionInfo":{"status":"ok","timestamp":1620063511456,"user_tz":-60,"elapsed":147487,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n","\n","input_ids_test_r= encoded_data_test_r['input_ids']\n","attention_masks_test_r= encoded_data_test_r['attention_mask']\n","\n","dataset_test_r= TensorDataset(input_ids_test_r, attention_masks_test_r,)\n","\n","dataloader_test_r = DataLoader(\n","    dataset_test_r, \n","    sampler=SequentialSampler(dataset_test_r), \n","    batch_size=4\n","    )"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8YkQkZZBGMV","executionInfo":{"status":"ok","timestamp":1620063511456,"user_tz":-60,"elapsed":147483,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["encoded_data_eval_r=tokenizerroberta.batch_encode_plus(\n","                        df_eval.values,              # Same we are doing for validation set.\n","                        add_special_tokens=True,\n","                        return_attention_mask=True,\n","                        padding='longest',\n","                        max_length=256,\n","                        truncation=True,\n","                        return_tensors='pt')\n","\n","\n","input_ids_eval_r= encoded_data_eval_r['input_ids']\n","attention_masks_eval_r= encoded_data_eval_r['attention_mask']\n","\n","dataset_eval_r= TensorDataset(input_ids_eval_r, attention_masks_eval_r,)\n","\n","dataloader_eval_r = DataLoader(\n","    dataset_eval_r, \n","    sampler=SequentialSampler(dataset_eval_r), \n","    batch_size=4\n","    )"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"z-yVOOOpN1ev","executionInfo":{"status":"ok","timestamp":1620063511457,"user_tz":-60,"elapsed":147480,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["import torch.nn.functional as F\n","\n","def predict_roberta(dataloader_test):\n","  \n","    robertamodel.eval()\n","    all_logits = []\n","    \n","    for batch in dataloader_test:\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {\n","            'input_ids':      batch[0],\n","            'attention_mask': batch[1],\n","            }\n","\n","        with torch.no_grad():        \n","            outputs = robertamodel(**inputs)\n","            \n","        # since we have no loss, the only thing returned is logits\n","        logits = outputs[0]\n","        all_logits.append(logits)\n","    \n","    all_logits = torch.cat(all_logits, dim=0)\n","    preds_flat = np.argmax(all_logits.cpu().numpy(), axis=1).flatten()\n","\n","    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n","\n","    # get highest prob dimension as prediction\n","    \n","    return preds_flat, probs"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q8bCcLrkOkex","executionInfo":{"status":"ok","timestamp":1620063551962,"user_tz":-60,"elapsed":187981,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds, probs=predict_roberta(dataloader_test_r)\n","probas.append(probs) \n","predictions.append(preds)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"tGyTQHRiBLX3","executionInfo":{"status":"ok","timestamp":1620063567878,"user_tz":-60,"elapsed":203893,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds, probs=predict_roberta(dataloader_eval_r )\n","probas_eval.append(probs)\n","predictions_eval.append(preds) "],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eC7IbuBVn69-"},"source":["**XLNet**"]},{"cell_type":"code","metadata":{"id":"-E6o9-19n6rM","executionInfo":{"status":"ok","timestamp":1620063567880,"user_tz":-60,"elapsed":203891,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from transformers import XLNetTokenizer\n","\n","tokenizerxlnet = XLNetTokenizer.from_pretrained(\n","                  'xlnet-base-cased') \n","\n","\n","encoded_data_test_x=tokenizerxlnet.batch_encode_plus(\n","                        df_test.values,              # Same we are doing for validation set.\n","                        add_special_tokens=True,\n","                        return_attention_mask=True,\n","                        padding='longest',\n","                        max_length=256,\n","                        truncation=True,\n","                        return_tensors='pt')"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4WpkkRJoWDT","executionInfo":{"status":"ok","timestamp":1620063567880,"user_tz":-60,"elapsed":203885,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n","\n","input_ids_test_x= encoded_data_test_x['input_ids']\n","attention_masks_test_x= encoded_data_test_x['attention_mask']\n","\n","dataset_test_x= TensorDataset(input_ids_test_x, attention_masks_test_x,)\n","\n","dataloader_test_x = DataLoader(\n","    dataset_test_x, \n","    sampler=SequentialSampler(dataset_test_x), \n","    batch_size=4\n","    )"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"K2-zkViqBWOt","executionInfo":{"status":"ok","timestamp":1620063568256,"user_tz":-60,"elapsed":204257,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["encoded_data_eval_x=tokenizerxlnet.batch_encode_plus(\n","                        df_eval.values,              # Same we are doing for validation set.\n","                        add_special_tokens=True,\n","                        return_attention_mask=True,\n","                        padding='longest',\n","                        max_length=256,\n","                        truncation=True,\n","                        return_tensors='pt')\n","\n","input_ids_eval_x= encoded_data_eval_x['input_ids']\n","attention_masks_eval_x= encoded_data_eval_x['attention_mask']\n","\n","dataset_eval_x= TensorDataset(input_ids_eval_x, attention_masks_eval_x,)\n","\n","dataloader_eval_x = DataLoader(\n","    dataset_eval_x, \n","    sampler=SequentialSampler(dataset_eval_x), \n","    batch_size=4\n","    )"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"GMMUe-rQoh69","executionInfo":{"status":"ok","timestamp":1620063568256,"user_tz":-60,"elapsed":204253,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["import torch.nn.functional as F\n","\n","def predict_xlnet(dataloader_test):\n","  \n","    xlnet.eval()\n","    all_logits = []\n","    \n","    for batch in dataloader_test:\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {\n","            'input_ids':      batch[0],\n","            'attention_mask': batch[1],\n","            }\n","\n","        with torch.no_grad():        \n","            outputs = xlnet(**inputs)\n","            \n","        # since we have no loss, the only thing returned is logits\n","        logits = outputs[0]\n","        all_logits.append(logits)\n","    \n","    all_logits = torch.cat(all_logits, dim=0)\n","    preds_flat = np.argmax(all_logits.cpu().numpy(), axis=1).flatten()\n","\n","    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n","\n","    # get highest prob dimension as prediction\n","    \n","    return preds_flat, probs"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXu_rRcyqfwy","executionInfo":{"status":"ok","timestamp":1620063617056,"user_tz":-60,"elapsed":253050,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds, probs=predict_xlnet(dataloader_test_x)\n","probas.append(probs) \n","predictions.append(preds)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ePifSoZBbtp","executionInfo":{"status":"ok","timestamp":1620063635923,"user_tz":-60,"elapsed":271913,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds, probs=predict_xlnet(dataloader_eval_x )\n","probas_eval.append(probs)\n","predictions_eval.append(preds) "],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m9C25de7AhrH"},"source":["**Concatenate all Predictions to get one row for each record**"]},{"cell_type":"code","metadata":{"id":"xAZL70Og_m-7","executionInfo":{"status":"ok","timestamp":1620063635923,"user_tz":-60,"elapsed":271910,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["predictions=np.array(predictions)\n","predictions_eval=np.array(predictions_eval)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nkj_zNgDBh5D","executionInfo":{"status":"ok","timestamp":1620063635924,"user_tz":-60,"elapsed":271906,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["probas=np.array(probas)\n","probas_eval=np.array(probas_eval)"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qhdMRgeRzaV1"},"source":["### **Method 1: Using Probabilities and Weighted Majority Voting**"]},{"cell_type":"markdown","metadata":{"id":"WDAkEw6G-4X1"},"source":["### **Finding Weights of each Model**\n","\n","Reference: https://machinelearningmastery.com/weighted-average-ensemble-for-deep-learning-neural-networks/"]},{"cell_type":"code","metadata":{"id":"zNeHWEpv-_h6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620063635924,"user_tz":-60,"elapsed":271903,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"20ec920c-5fc8-40e0-e7d3-f102443ab8c7"},"source":["import random\n","from numpy.linalg import norm\n","\n","weights = [random.uniform(0, 1)for _ in range(4)]\n","l1norm = norm(weights,1)\n","weights= weights / l1norm\n","print(weights)\n"],"execution_count":37,"outputs":[{"output_type":"stream","text":["[0.25167691 0.11057583 0.24349748 0.39424978]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ss7q1ew5BGd1"},"source":["**Calculate Accuracy with Initial Weights**"]},{"cell_type":"code","metadata":{"id":"jLigO4K8A4JN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620063635925,"user_tz":-60,"elapsed":271899,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"f93a79a9-f90e-424f-d171-3eb457d95610"},"source":["from sklearn.metrics import accuracy_score\n","\n","weightedavg = np.average(probas, axis=0, weights=weights)\n","result = np.argmax(weightedavg, axis=1)\n","accuracy_score(result,sentiment_test)\n"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9047619047619048"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"3CYA5Q-XHqU1"},"source":["**Find Optimal Weights**"]},{"cell_type":"code","metadata":{"id":"V0Eb16LRHx1X","executionInfo":{"status":"ok","timestamp":1620063635925,"user_tz":-60,"elapsed":271894,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from numpy.linalg import norm\n","\n","def loss_func(weights):\n","  l1norm = norm(weights,1)\n","  weights= weights / l1norm\n","  weightedavg = np.average(probas, axis=0, weights=weights)\n","  result = np.argmax(weightedavg, axis=1)\n","  return 1 - accuracy_score(result,sentiment_test)"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"jKuy-YAhK10r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620063636322,"user_tz":-60,"elapsed":272287,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"a69289ac-6dbc-42cb-9371-e9e69910b3f9"},"source":["from scipy.optimize import differential_evolution\n","\n","bound_w = [(0.0, 1.0)  for _ in range(4)]\n","result = differential_evolution(loss_func, bound_w, maxiter=1000000, tol=1e-7,disp=True)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["differential_evolution step 1: f(x)= 0.0857143\n","differential_evolution step 2: f(x)= 0.0857143\n","differential_evolution step 3: f(x)= 0.0857143\n","differential_evolution step 4: f(x)= 0.0857143\n","differential_evolution step 5: f(x)= 0.0857143\n","differential_evolution step 6: f(x)= 0.0857143\n","differential_evolution step 7: f(x)= 0.0857143\n","differential_evolution step 8: f(x)= 0.0857143\n","differential_evolution step 9: f(x)= 0.0857143\n","differential_evolution step 10: f(x)= 0.0857143\n","differential_evolution step 11: f(x)= 0.0857143\n","differential_evolution step 12: f(x)= 0.0857143\n","differential_evolution step 13: f(x)= 0.0857143\n","differential_evolution step 14: f(x)= 0.0857143\n","differential_evolution step 15: f(x)= 0.0857143\n","differential_evolution step 16: f(x)= 0.0857143\n","differential_evolution step 17: f(x)= 0.0857143\n","differential_evolution step 18: f(x)= 0.0857143\n","differential_evolution step 19: f(x)= 0.0857143\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AXE6RfLPNnhr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620063636322,"user_tz":-60,"elapsed":272280,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"4d39e867-ca39-43aa-d128-8a70c406c816"},"source":["weights=result['x']\n","l1norm = norm(weights,1)\n","final_weights= weights / l1norm\n","print(final_weights)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["[0.22928194 0.1065001  0.34702193 0.31719603]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CgytNfjmORpw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620063636323,"user_tz":-60,"elapsed":272277,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"f46596ce-912c-43b4-8f64-69c8504a3213"},"source":["weightedavg = np.average(probas, axis=0, weights=final_weights)\n","result = np.argmax(weightedavg, axis=1)\n","print(accuracy_score(result,sentiment_test))"],"execution_count":42,"outputs":[{"output_type":"stream","text":["0.9142857142857143\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"olapwsR8Chr_","executionInfo":{"status":"ok","timestamp":1620063636323,"user_tz":-60,"elapsed":272272,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"d79dd699-0356-4e8f-c409-ac94a71ce1b7"},"source":["weightedavg_eval = np.average(probas_eval, axis=0, weights=weights)\n","result_eval = np.argmax(weightedavg_eval, axis=1)\n","print(accuracy_score(result_eval,sentiment_eval))"],"execution_count":43,"outputs":[{"output_type":"stream","text":["0.8444444444444444\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ddTc9l6LUdvc"},"source":["### **Method 2 - Using Predictions Directly for Majority Vote Method**"]},{"cell_type":"code","metadata":{"id":"02Fmryw3Ue87","executionInfo":{"status":"ok","timestamp":1620063687687,"user_tz":-60,"elapsed":633,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["predictions_t=predictions.T\n","predictions_eval_t=predictions_eval.T"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49r24GRoUhmm","executionInfo":{"status":"ok","timestamp":1620063701092,"user_tz":-60,"elapsed":644,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"dbf6d193-ac91-4401-b054-9d92f799e7a1"},"source":["final_preds=np.array([np.argmax(np.bincount(predictions_t[i],weights=[1,1,1,1])) for i in range(predictions_t.shape[0])])\n","accuracy_score(final_preds,sentiment_test)"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NkrQySPPUlRk","executionInfo":{"status":"ok","timestamp":1620063716851,"user_tz":-60,"elapsed":670,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"32d8193f-caf1-499f-d4c1-7b45f71e4db5"},"source":["final_preds_eval=np.array([np.argmax(np.bincount(predictions_eval_t[i],weights=[1,1,1,1])) for i in range(predictions_eval_t.shape[0])])\n","accuracy_score(final_preds_eval,sentiment_eval)"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8444444444444444"]},"metadata":{"tags":[]},"execution_count":46}]}]}