{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ensemble_model-V2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"x-pWzJpM16x-"},"source":["# Final Masters Project\n","\n","## Name: Sreekanth Palagiri, Student ID: R00184198\n","\n","## Project Topic: Evaluation of Ensemble Approach for Sentiment Analysis on a Small Dataset\n","\n","##NoteBook: Ensemble of Models\n"]},{"cell_type":"markdown","metadata":{"id":"-XI7x-Qu2OZB"},"source":["### **Mount google drive**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHAsUhPE2i45","executionInfo":{"status":"ok","timestamp":1620065972271,"user_tz":-60,"elapsed":722,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"64706438-c37f-455e-829e-fe32060e131a"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1qkvvFpJFzEo","executionInfo":{"status":"ok","timestamp":1620065977251,"user_tz":-60,"elapsed":5691,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"a49b3bc0-098c-4f50-ca7d-0cdf479bae8f"},"source":["!pip install flair\n","!pip install transformer"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: flair in /usr/local/lib/python3.7/dist-packages (0.8.0.post1)\n","Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3.3)\n","Requirement already satisfied: gdown==3.12.2 in /usr/local/lib/python3.7/dist-packages (from flair) (3.12.2)\n","Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n","Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.5.1)\n","Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.6.4)\n","Requirement already satisfied: janome in /usr/local/lib/python3.7/dist-packages (from flair) (0.4.1)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n","Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from flair) (1.5.10)\n","Requirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.19.5)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.1)\n","Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n","Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.95)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from flair) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from flair) (0.0.8)\n","Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.8)\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n","Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.7.0)\n","Requirement already satisfied: torch<=1.7.1,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.7.1)\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.41.1)\n","Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from flair) (1.2.12)\n","Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.0.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.5.1)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.11.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (1.4.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (3.10.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.10.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (20.9)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.0.45)\n","Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.0.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.7.1,>=1.5.0->flair) (3.7.4.3)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=4.0.0->flair) (3.4.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement transformer (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for transformer\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Rl8ATw853CaQ"},"source":["### **Load Data and Preprocess**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272},"id":"KSX3LEp51eTF","executionInfo":{"status":"ok","timestamp":1620065977252,"user_tz":-60,"elapsed":5684,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"f1372862-ba58-459b-c8f0-fd98ea1bb434"},"source":["import pandas as pd\n","import numpy as np\n","\n","df=pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/Masters Project/VMDataset/Export_loop-sentiment-pos-neg-train_05112020000000.csv\")\n","print(df.groupby(['label']).size())\n","df.head()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["label\n","Negative     887\n","Positive    1013\n","dtype: int64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Negative</td>\n","      <td>No one cares about marketing slides - a techni...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Positive</td>\n","      <td>Are all three hosts providing storage/capacity...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Negative</td>\n","      <td>would loved to had managed to get down to the ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Negative</td>\n","      <td>Vending machine at work is out of Dasani water...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Positive</td>\n","      <td>RT @VMwareEdu: Paul Maritz, CEO and President ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      label                                               text\n","0  Negative  No one cares about marketing slides - a techni...\n","1  Positive  Are all three hosts providing storage/capacity...\n","2  Negative  would loved to had managed to get down to the ...\n","3  Negative  Vending machine at work is out of Dasani water...\n","4  Positive  RT @VMwareEdu: Paul Maritz, CEO and President ..."]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"uRkI6SHk3Kwy"},"source":["**Preprocessor to Remove all special characters except emoticons**"]},{"cell_type":"code","metadata":{"id":"aLrMJ40C3GRb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620065977253,"user_tz":-60,"elapsed":5677,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"1f4eb403-d6ef-441c-bc5a-d1b53a318569"},"source":["import re\n","\n","def preprocessor(text):\n","    text = re.sub('<[^>]*>', '', text)\n","    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n","    text = re.sub('[^A-Za-z0-9\\']+', ' ', text.lower()) +\\\n","        ' '.join(emoticons).replace('-', '')\n","    return text\n","\n","#'[^A-Za-z0-9\\']+'\n","\n","print(df['text'][19])\n","print(preprocessor(df['text'][19]))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Kristina,  Any updates from your side ? I volunteer for beta test :)  - really need that app running as workaround are driving me nuts ....\n","kristina any updates from your side i volunteer for beta test really need that app running as workaround are driving me nuts :)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VLkO7GvP3Vnp","executionInfo":{"status":"ok","timestamp":1620065977253,"user_tz":-60,"elapsed":5671,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["df['text'] = df['text'].apply(preprocessor)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"y9rlhWdBZHn2","executionInfo":{"status":"ok","timestamp":1620065977657,"user_tz":-60,"elapsed":6069,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"01eac349-8c4f-4a2b-a8fe-e2b124c64d6d"},"source":["from sklearn import preprocessing\n","\n","le = preprocessing.LabelEncoder()\n","df['Sentiment']=le.fit_transform(df['label'])\n","df.head(10)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>text</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Negative</td>\n","      <td>no one cares about marketing slides a technica...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Positive</td>\n","      <td>are all three hosts providing storage capacity...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Negative</td>\n","      <td>would loved to had managed to get down to the ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Negative</td>\n","      <td>vending machine at work is out of dasani water...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Positive</td>\n","      <td>rt vmwareedu paul maritz ceo and president of ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Positive</td>\n","      <td>had few folks ask if you're interested johnny ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Positive</td>\n","      <td>get notified of the latest vsan patch releases...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Negative</td>\n","      <td>end of general support is 3 12 2020 6 5 and 6 ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Negative</td>\n","      <td>placed 4th in funrun today in the 17 39 age gr...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Positive</td>\n","      <td>yup guys being currently under nda know this f...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      label                                               text  Sentiment\n","0  Negative  no one cares about marketing slides a technica...          0\n","1  Positive  are all three hosts providing storage capacity...          1\n","2  Negative  would loved to had managed to get down to the ...          0\n","3  Negative  vending machine at work is out of dasani water...          0\n","4  Positive  rt vmwareedu paul maritz ceo and president of ...          1\n","5  Positive  had few folks ask if you're interested johnny ...          1\n","6  Positive  get notified of the latest vsan patch releases...          1\n","7  Negative  end of general support is 3 12 2020 6 5 and 6 ...          0\n","8  Negative  placed 4th in funrun today in the 17 39 age gr...          0\n","9  Positive  yup guys being currently under nda know this f...          1"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"0IESLSGz3jwd"},"source":["### **Seperate Into Train, Test and Validation Sets**"]},{"cell_type":"code","metadata":{"id":"2A-engB1gB76","executionInfo":{"status":"ok","timestamp":1620065977657,"user_tz":-60,"elapsed":6062,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["df_train=df.iloc[0:int(len(df)*0.85)].reset_index(drop=True)\n","df_test=df.iloc[int(len(df)*0.85):].reset_index(drop=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"d5UA1-C53jBV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620065977658,"user_tz":-60,"elapsed":6059,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"2b504664-71eb-457d-93ae-bc8150b6eafc"},"source":["from sklearn.model_selection import train_test_split\n","\n","df_test, df_eval, sentiment_test, sentiment_eval = train_test_split(df_test['text'], df_test['Sentiment'], \n","                                                                      random_state=1, test_size=.30, \n","                                                                      shuffle=False)\n","\n","\n","print('Length of train set:',len(df_test),'Length of test set:',len(df_eval))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Length of train set: 199 Length of test set: 86\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-KuyngUI31ZH"},"source":["### **Load All Models and Predict to prepare for Emsemble Model**\n","\n","****"]},{"cell_type":"code","metadata":{"id":"-TNIBAz0oBqa","executionInfo":{"status":"ok","timestamp":1620065977658,"user_tz":-60,"elapsed":6052,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["def tokenizer(text):\n","  return [stemmer.stem(word) for word in text.split()]"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qGLMBCvGEo9S"},"source":["**Logistic**"]},{"cell_type":"code","metadata":{"id":"T7eRk4v24BJD","executionInfo":{"status":"ok","timestamp":1620065977659,"user_tz":-60,"elapsed":6048,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from joblib import load\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","tfidf=load('/content/gdrive/My Drive/Colab Notebooks/Masters Project/VMDataset/Models/tfidf_logistic.joblib')\n","model_reg=load('/content/gdrive/My Drive/Colab Notebooks/Masters Project/VMDataset/Models/clf_logistic.joblib')"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7zmwZUnHEt6v"},"source":["**LSTM Model**"]},{"cell_type":"code","metadata":{"id":"T1Oi8MUn4LWV","executionInfo":{"status":"ok","timestamp":1620065981229,"user_tz":-60,"elapsed":9614,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["import io\n","import json\n","from tensorflow import keras\n","\n","with open('/content/gdrive/My Drive/Colab Notebooks/Masters Project/VMDataset/Models/tokenizer.json') as f:\n","    data = json.load(f)\n","    tokenizer = keras.preprocessing.text.tokenizer_from_json(data)\n","\n","model_lstm=keras.models.load_model('/content/gdrive/My Drive/Colab Notebooks/Masters Project/VMDataset/Models/model_lstm.h5')"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hNYhoDg34wGH"},"source":["**Flair Model**\n","\n"]},{"cell_type":"code","metadata":{"id":"kAHU6zQXE-rD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620065991036,"user_tz":-60,"elapsed":19417,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"1e48b67a-c004-4d05-9e36-d8d4d96dbb30"},"source":["from flair.models import TextClassifier\n","\n","model_flair=TextClassifier.load('/content/gdrive/My Drive/Colab Notebooks/Masters Project/VMDataset/Models/resources/taggers/trec/best-model.pt')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["2021-05-03 18:19:42,964 loading file /content/gdrive/My Drive/Colab Notebooks/Masters Project/VMDataset/Models/resources/taggers/trec/best-model.pt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OUHjiyzS-JYJ"},"source":["**Bert Model**"]},{"cell_type":"code","metadata":{"id":"FbwwQudm5Icp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620066006151,"user_tz":-60,"elapsed":34525,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"e1a50a88-2264-44c0-e5ba-1693f2d8f016"},"source":["import torch\n","from transformers import BertForSequenceClassification \n","\n","bertmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n","                                                      num_labels=len(df.label.unique()),\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)\n","\n","bertmodel.load_state_dict(torch.load('/content/gdrive/My Drive/Colab Notebooks/Masters Project/VMDataset/Models/BERT_ft_epoch8.model',map_location=torch.device('cpu')))\n","\n","device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","bertmodel.to(device)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"n5fYFCYvK2da"},"source":["**roBERTA Model**"]},{"cell_type":"code","metadata":{"id":"dO5Al_YUK8kr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620066013524,"user_tz":-60,"elapsed":41891,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"96556c85-4840-4605-c983-c3ff24003f4a"},"source":["import torch\n","from transformers import RobertaForSequenceClassification \n","\n","robertamodel = RobertaForSequenceClassification.from_pretrained(\"roberta-base\",\n","                                                      num_labels=len(df.label.unique()),\n","                                                      output_attentions=False,\n","                                                      output_hidden_states=False)\n","\n","robertamodel.load_state_dict(torch.load('/content/gdrive/My Drive/Colab Notebooks/Masters Project/VMDataset/Models/roBERTa_ft_epoch7.model',map_location=torch.device('cpu')))\n","\n","device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","robertamodel.to(device)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"cAu-6YAw2qyB"},"source":["### **Getting Predictions on Test Data Set**\n","\n","**Logistic Models**"]},{"cell_type":"code","metadata":{"id":"LmgjoUQb6zMc","executionInfo":{"status":"ok","timestamp":1620066013916,"user_tz":-60,"elapsed":42277,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from nltk.stem.porter import PorterStemmer\n","\n","stemmer = PorterStemmer()\n","\n","def stemm(text):\n","  return ' '.join([stemmer.stem(word) for word in text.split()])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"77RDeD2Qm6Kj","executionInfo":{"status":"ok","timestamp":1620066013917,"user_tz":-60,"elapsed":42274,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["df_test_stem=df_test.apply(stemm)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"IuPk2Epu2ysT","executionInfo":{"status":"ok","timestamp":1620066014179,"user_tz":-60,"elapsed":42532,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["probas=[]\n","probas_eval=[]\n","\n","probas.append(model_reg.predict_proba(tfidf.transform(df_test)))\n","probas_eval.append(model_reg.predict_proba(tfidf.transform(df_eval)))"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"o8QBITy4Ajag","executionInfo":{"status":"ok","timestamp":1620066014442,"user_tz":-60,"elapsed":42791,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["predictions=[]\n","predictions_eval=[]\n","\n","predictions.append(model_reg.predict(tfidf.transform(df_test)))\n","predictions_eval.append(model_reg.predict(tfidf.transform(df_eval)))"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dPh5kohE9cPK"},"source":["**LSTM Model**"]},{"cell_type":"code","metadata":{"id":"vLFd-nO89p2I","executionInfo":{"status":"ok","timestamp":1620066015911,"user_tz":-60,"elapsed":44256,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","max_seq_length= 500\n","\n","test_sequences = tokenizer.texts_to_sequences(df_test)\n","test_sequences = pad_sequences(test_sequences,maxlen =max_seq_length)\n","\n","lstm_pred=model_lstm.predict(test_sequences)\n","probas.append(lstm_pred)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"v2Tb0IphqtDy","executionInfo":{"status":"ok","timestamp":1620066016329,"user_tz":-60,"elapsed":44670,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["max_seq_length= 500\n","\n","eval_sequences = tokenizer.texts_to_sequences(df_eval)\n","eval_sequences = pad_sequences(eval_sequences,maxlen =max_seq_length)\n","\n","lstm_pred_eval=model_lstm.predict(eval_sequences)\n","probas_eval.append(lstm_pred_eval)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"fPDP_k2HAuZi","executionInfo":{"status":"ok","timestamp":1620066016329,"user_tz":-60,"elapsed":44666,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds = np.argmax(lstm_pred, axis=1).flatten()\n","predictions.append(preds)\n","\n","preds= np.argmax(lstm_pred_eval, axis=1).flatten()\n","predictions_eval.append(preds)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9-qYuZk5Ar-_"},"source":["**Flair Model**"]},{"cell_type":"code","metadata":{"id":"LX-qP9bGAW6r","executionInfo":{"status":"ok","timestamp":1620066036079,"user_tz":-60,"elapsed":64411,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from flair.data import Sentence\n","\n","results=[]\n","for i in df_test.index:\n","    sentence=Sentence(df_test[i])\n","    model_flair.predict(sentence)\n","    if sentence.get_labels()[0].value=='Positive':\n","      score=1-sentence.get_labels()[0].score\n","    else:\n","      score=sentence.get_labels()[0].score\n","    results.append([score,1-score])\n","probas.append(np.array(results))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"aq83Fqk4y3_D","executionInfo":{"status":"ok","timestamp":1620066036082,"user_tz":-60,"elapsed":64411,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds = np.argmax(np.array(results), axis=1).flatten()\n","predictions.append(preds)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"WqWaPw4cqzZr","executionInfo":{"status":"ok","timestamp":1620066044632,"user_tz":-60,"elapsed":72957,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from flair.data import Sentence\n","\n","results=[]\n","for i in df_eval.index:\n","    sentence=Sentence(df_eval[i])\n","    model_flair.predict(sentence)\n","    if sentence.get_labels()[0].value=='Positive':\n","      score=1-sentence.get_labels()[0].score\n","    else:\n","      score=sentence.get_labels()[0].score\n","    results.append([score,1-score])\n","probas_eval.append(np.array(results))"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"ocir8xOEBHzH","executionInfo":{"status":"ok","timestamp":1620066044633,"user_tz":-60,"elapsed":72954,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds = np.argmax(np.array(results), axis=1).flatten()\n","predictions_eval.append(preds)"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Myc8tQ7jKfFm"},"source":["**Bert Model**"]},{"cell_type":"code","metadata":{"id":"Aky8SJ0SKUsy","executionInfo":{"status":"ok","timestamp":1620066045791,"user_tz":-60,"elapsed":74109,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from transformers import BertTokenizer\n","\n","tokenizerbert = BertTokenizer.from_pretrained(\n","                  'bert-base-uncased',\n","                  do_lower_case=True) \n","\n","\n","encoded_data_test=tokenizerbert.batch_encode_plus(\n","                        df_test.values,              # Same we are doing for validation set.\n","                        add_special_tokens=True,\n","                        return_attention_mask=True,\n","                        padding='longest',\n","                        max_length=256,\n","                        truncation=True,\n","                        return_tensors='pt')"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"GhD8kC7xLFhl","executionInfo":{"status":"ok","timestamp":1620066045792,"user_tz":-60,"elapsed":74103,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n","\n","input_ids_test= encoded_data_test['input_ids']\n","attention_masks_test= encoded_data_test['attention_mask']\n","\n","dataset_test= TensorDataset(input_ids_test, attention_masks_test,)\n","\n","dataloader_test = DataLoader(\n","    dataset_test, \n","    sampler=SequentialSampler(dataset_test), \n","    batch_size=4\n","    )"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y6cksWr-q8IX","executionInfo":{"status":"ok","timestamp":1620066045792,"user_tz":-60,"elapsed":74100,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["encoded_data_eval=tokenizerbert.batch_encode_plus(\n","                        df_eval.values,              # Same we are doing for validation set.\n","                        add_special_tokens=True,\n","                        return_attention_mask=True,\n","                        padding='longest',\n","                        max_length=256,\n","                        truncation=True,\n","                        return_tensors='pt')\n","\n","input_ids_eval= encoded_data_eval['input_ids']\n","attention_masks_eval= encoded_data_eval['attention_mask']\n","\n","dataset_eval= TensorDataset(input_ids_eval, attention_masks_eval,)\n","\n","dataloader_eval = DataLoader(\n","    dataset_eval, \n","    sampler=SequentialSampler(dataset_eval), \n","    batch_size=4\n","    )"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"dqC8_gq1MRmt","executionInfo":{"status":"ok","timestamp":1620066045793,"user_tz":-60,"elapsed":74097,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["import torch.nn.functional as F\n","\n","def predict_bert(dataloader_test):\n","  \n","    bertmodel.eval()\n","    all_logits = []\n","    \n","    for batch in dataloader_test:\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {\n","            'input_ids':      batch[0],\n","            'attention_mask': batch[1],\n","            }\n","\n","        with torch.no_grad():        \n","            outputs = bertmodel(**inputs)\n","            \n","        # since we have no loss, the only thing returned is logits\n","        logits = outputs[0]\n","        all_logits.append(logits)\n","    \n","    all_logits = torch.cat(all_logits, dim=0)\n","    preds_flat = np.argmax(all_logits.cpu().numpy(), axis=1).flatten()\n","\n","    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n","\n","    # get highest prob dimension as prediction\n","    \n","    return preds_flat, probs\n","\n"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ex20mNazM5oD","executionInfo":{"status":"ok","timestamp":1620066218154,"user_tz":-60,"elapsed":246455,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds, probs=predict_bert(dataloader_test)\n","probas.append(probs) \n","predictions.append(preds)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"1NLPUD6OrRhp","executionInfo":{"status":"ok","timestamp":1620066270916,"user_tz":-60,"elapsed":299213,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds, probs=predict_bert(dataloader_eval)\n","probas_eval.append(probs) \n","predictions_eval.append(preds)"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n3Ltb6sFMCEU"},"source":["**roBERTa Model**"]},{"cell_type":"code","metadata":{"id":"5UHr8YkbMHlZ","executionInfo":{"status":"ok","timestamp":1620066271859,"user_tz":-60,"elapsed":300153,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from transformers import RobertaTokenizer\n","\n","tokenizerroberta = RobertaTokenizer.from_pretrained(\n","                  'roberta-base') \n","\n","\n","encoded_data_test_r=tokenizerroberta.batch_encode_plus(\n","                        df_test.values,              # Same we are doing for validation set.\n","                        add_special_tokens=True,\n","                        return_attention_mask=True,\n","                        padding='longest',\n","                        max_length=256,\n","                        truncation=True,\n","                        return_tensors='pt')"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z6xgp95Crgk7","executionInfo":{"status":"ok","timestamp":1620066271862,"user_tz":-60,"elapsed":300150,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["encoded_data_eval_r=tokenizerroberta.batch_encode_plus(\n","                        df_eval.values,              # Same we are doing for validation set.\n","                        add_special_tokens=True,\n","                        return_attention_mask=True,\n","                        padding='longest',\n","                        max_length=256,\n","                        truncation=True,\n","                        return_tensors='pt')"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICJ24_4_NkIq","executionInfo":{"status":"ok","timestamp":1620066271863,"user_tz":-60,"elapsed":300147,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n","\n","input_ids_test_r= encoded_data_test_r['input_ids']\n","attention_masks_test_r= encoded_data_test_r['attention_mask']\n","\n","dataset_test_r= TensorDataset(input_ids_test_r, attention_masks_test_r,)\n","\n","dataloader_test_r = DataLoader(\n","    dataset_test_r, \n","    sampler=SequentialSampler(dataset_test_r), \n","    batch_size=4\n","    )"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"vfCTpMXkrppC","executionInfo":{"status":"ok","timestamp":1620066271863,"user_tz":-60,"elapsed":300142,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["input_ids_eval_r= encoded_data_eval_r['input_ids']\n","attention_masks_eval_r= encoded_data_eval_r['attention_mask']\n","\n","dataset_eval_r= TensorDataset(input_ids_eval_r, attention_masks_eval_r,)\n","\n","dataloader_eval_r = DataLoader(\n","    dataset_eval_r, \n","    sampler=SequentialSampler(dataset_eval_r), \n","    batch_size=4\n","    )"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"z-yVOOOpN1ev","executionInfo":{"status":"ok","timestamp":1620066271863,"user_tz":-60,"elapsed":300138,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["import torch.nn.functional as F\n","\n","def predict_roberta(dataloader_test):\n","  \n","    robertamodel.eval()\n","    all_logits = []\n","    \n","    for batch in dataloader_test:\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {\n","            'input_ids':      batch[0],\n","            'attention_mask': batch[1],\n","            }\n","\n","        with torch.no_grad():        \n","            outputs = robertamodel(**inputs)\n","            \n","        # since we have no loss, the only thing returned is logits\n","        logits = outputs[0]\n","        all_logits.append(logits)\n","    \n","    all_logits = torch.cat(all_logits, dim=0)\n","    preds_flat = np.argmax(all_logits.cpu().numpy(), axis=1).flatten()\n","\n","    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n","\n","    # get highest prob dimension as prediction\n","    \n","    return preds_flat, probs"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q8bCcLrkOkex","executionInfo":{"status":"ok","timestamp":1620066443031,"user_tz":-60,"elapsed":471302,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds, probs=predict_roberta(dataloader_test_r)\n","probas.append(probs) \n","predictions.append(preds)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"bK_W7fmYr9GV","executionInfo":{"status":"ok","timestamp":1620066491309,"user_tz":-60,"elapsed":519576,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["preds, probs=predict_roberta(dataloader_eval_r )\n","probas_eval.append(probs)\n","predictions_eval.append(preds) "],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m9C25de7AhrH"},"source":["**Concatenate all Predictions to get one row for each record**"]},{"cell_type":"code","metadata":{"id":"xAZL70Og_m-7","executionInfo":{"status":"ok","timestamp":1620066491315,"user_tz":-60,"elapsed":519579,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["predictions=np.array(predictions)\n","predictions_eval=np.array(predictions_eval)"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"O1vcwaLKsLmF","executionInfo":{"status":"ok","timestamp":1620066491315,"user_tz":-60,"elapsed":519576,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["probas=np.array(probas)\n","probas_eval=np.array(probas_eval)"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qhdMRgeRzaV1"},"source":["### **Method 1: Using Probabilities and Weighted Majority Voting**"]},{"cell_type":"markdown","metadata":{"id":"WDAkEw6G-4X1"},"source":["### **Finding Weights of each Model**\n","\n","Reference: https://machinelearningmastery.com/weighted-average-ensemble-for-deep-learning-neural-networks/"]},{"cell_type":"code","metadata":{"id":"zNeHWEpv-_h6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620066491315,"user_tz":-60,"elapsed":519573,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"5fbdbdf8-e1a4-4fe0-a520-d7cf0ce1187d"},"source":["import random\n","from numpy.linalg import norm\n","\n","weights = [random.uniform(0, 1)for _ in range(5)]\n","l1norm = norm(weights,1)\n","weights= weights / l1norm\n","print(weights)\n"],"execution_count":41,"outputs":[{"output_type":"stream","text":["[0.26396173 0.1378903  0.29387277 0.06698499 0.2372902 ]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ss7q1ew5BGd1"},"source":["**Calculate Accuracy with Initial Weights**"]},{"cell_type":"code","metadata":{"id":"jLigO4K8A4JN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620066491316,"user_tz":-60,"elapsed":519568,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"7bc81431-d43d-4f2e-9d77-270e0ec3ff46"},"source":["from sklearn.metrics import accuracy_score\n","\n","weightedavg = np.average(probas, axis=0, weights=weights)\n","result = np.argmax(weightedavg, axis=1)\n","accuracy_score(result,sentiment_test)\n"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8693467336683417"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ou0TM1-0hPa8","executionInfo":{"status":"ok","timestamp":1620066491316,"user_tz":-60,"elapsed":519563,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"5c7045b2-0713-44a6-fe95-aaad664b0043"},"source":["weightedavg_eval = np.average(probas_eval, axis=0, weights=weights)\n","result_eval = np.argmax(weightedavg_eval, axis=1)\n","print(accuracy_score(result_eval,sentiment_eval))"],"execution_count":43,"outputs":[{"output_type":"stream","text":["0.8837209302325582\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3CYA5Q-XHqU1"},"source":["**Find Optimal Weights**"]},{"cell_type":"code","metadata":{"id":"V0Eb16LRHx1X","executionInfo":{"status":"ok","timestamp":1620066491317,"user_tz":-60,"elapsed":519557,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["from numpy.linalg import norm\n","\n","def loss_func(weights):\n","  l1norm = norm(weights,1)\n","  weights= weights / l1norm\n","  weightedavg = np.average(probas, axis=0, weights=weights)\n","  result = np.argmax(weightedavg, axis=1)\n","  return 1 - accuracy_score(result,sentiment_test)"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"jKuy-YAhK10r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620066492927,"user_tz":-60,"elapsed":521163,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"7e1834c0-b0be-41a9-a3e6-68549c465443"},"source":["from scipy.optimize import differential_evolution\n","\n","bound_w = [(0.0, 1.0)  for _ in range(5)]\n","result = differential_evolution(loss_func, bound_w, maxiter=1000000, tol=1e-7,disp=True)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["differential_evolution step 1: f(x)= 0.115578\n","differential_evolution step 2: f(x)= 0.115578\n","differential_evolution step 3: f(x)= 0.115578\n","differential_evolution step 4: f(x)= 0.115578\n","differential_evolution step 5: f(x)= 0.115578\n","differential_evolution step 6: f(x)= 0.115578\n","differential_evolution step 7: f(x)= 0.110553\n","differential_evolution step 8: f(x)= 0.110553\n","differential_evolution step 9: f(x)= 0.110553\n","differential_evolution step 10: f(x)= 0.110553\n","differential_evolution step 11: f(x)= 0.110553\n","differential_evolution step 12: f(x)= 0.110553\n","differential_evolution step 13: f(x)= 0.110553\n","differential_evolution step 14: f(x)= 0.110553\n","differential_evolution step 15: f(x)= 0.110553\n","differential_evolution step 16: f(x)= 0.110553\n","differential_evolution step 17: f(x)= 0.110553\n","differential_evolution step 18: f(x)= 0.110553\n","differential_evolution step 19: f(x)= 0.110553\n","differential_evolution step 20: f(x)= 0.110553\n","differential_evolution step 21: f(x)= 0.110553\n","differential_evolution step 22: f(x)= 0.110553\n","differential_evolution step 23: f(x)= 0.110553\n","differential_evolution step 24: f(x)= 0.110553\n","differential_evolution step 25: f(x)= 0.110553\n","differential_evolution step 26: f(x)= 0.110553\n","differential_evolution step 27: f(x)= 0.110553\n","differential_evolution step 28: f(x)= 0.110553\n","differential_evolution step 29: f(x)= 0.110553\n","differential_evolution step 30: f(x)= 0.110553\n","differential_evolution step 31: f(x)= 0.110553\n","differential_evolution step 32: f(x)= 0.110553\n","differential_evolution step 33: f(x)= 0.110553\n","differential_evolution step 34: f(x)= 0.110553\n","differential_evolution step 35: f(x)= 0.110553\n","differential_evolution step 36: f(x)= 0.110553\n","differential_evolution step 37: f(x)= 0.110553\n","differential_evolution step 38: f(x)= 0.110553\n","differential_evolution step 39: f(x)= 0.110553\n","differential_evolution step 40: f(x)= 0.110553\n","differential_evolution step 41: f(x)= 0.110553\n","differential_evolution step 42: f(x)= 0.110553\n","differential_evolution step 43: f(x)= 0.110553\n","differential_evolution step 44: f(x)= 0.110553\n","differential_evolution step 45: f(x)= 0.110553\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AXE6RfLPNnhr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620066492928,"user_tz":-60,"elapsed":521158,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"35eac43d-94c6-4579-a41c-c66bf05a72e5"},"source":["weights=result['x']\n","l1norm = norm(weights,1)\n","final_weights= weights / l1norm\n","print(final_weights)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["[0.05991295 0.03501354 0.45441749 0.39248996 0.05816605]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CgytNfjmORpw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620066492928,"user_tz":-60,"elapsed":521152,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"e3ff7491-08e1-4f40-81d3-ffed6b5a1f0f"},"source":["weightedavg = np.average(probas, axis=0, weights=final_weights)\n","result = np.argmax(weightedavg, axis=1)\n","print(accuracy_score(result,sentiment_test))"],"execution_count":47,"outputs":[{"output_type":"stream","text":["0.8894472361809045\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ztaV1V8SvUun"},"source":["### **Test on Evaluation Set**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZi__FPkw0Fq","executionInfo":{"status":"ok","timestamp":1620066492929,"user_tz":-60,"elapsed":521148,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"836a765d-5926-4f22-eb3e-dccf45e83ec7"},"source":["weightedavg_eval = np.average(probas_eval , axis=0, weights=weights)\n","result_eval = np.argmax(weightedavg_eval, axis=1)\n","print(accuracy_score(result_eval,sentiment_eval))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["0.9186046511627907\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BHH36W9lDev1"},"source":["### **Method 2: Majority Voting using direct predictions**"]},{"cell_type":"code","metadata":{"id":"Sy2lNp75DlMP","executionInfo":{"status":"ok","timestamp":1620066492929,"user_tz":-60,"elapsed":521140,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}}},"source":["predictions_t=predictions.T\n","predictions_eval_t=predictions_eval.T"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DhccKlJVDlrH","executionInfo":{"status":"ok","timestamp":1620066492930,"user_tz":-60,"elapsed":521137,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"b13fde00-a8b5-4ac5-9a65-9c0718a43b14"},"source":["final_preds=np.array([np.argmax(np.bincount(predictions_t[i],weights=[1,1,1,1,1])) for i in range(predictions_t.shape[0])])\n","accuracy_score(final_preds,sentiment_test)"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.864321608040201"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KiNdUNbkDpEH","executionInfo":{"status":"ok","timestamp":1620066493476,"user_tz":-60,"elapsed":521677,"user":{"displayName":"Sreekanth Palagiri","photoUrl":"","userId":"07452100641617756169"}},"outputId":"84e9d609-5b47-4c98-bade-6ea74a730e49"},"source":["final_preds_eval=np.array([np.argmax(np.bincount(predictions_eval_t[i],weights=[1,1,1,1,1])) for i in range(predictions_eval_t.shape[0])])\n","accuracy_score(final_preds_eval,sentiment_eval)"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.872093023255814"]},"metadata":{"tags":[]},"execution_count":51}]}]}